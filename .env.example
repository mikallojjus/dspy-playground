# =============================================================================
# Database Configuration
# =============================================================================
DATABASE_URL=postgresql://user:password@localhost:5432/podcast_db

# =============================================================================
# Ollama Configuration
# =============================================================================
OLLAMA_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b-instruct-q4_0
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# =============================================================================
# Reranker Service
# =============================================================================
ENABLE_RERANKER=true
RERANKER_URL=http://localhost:8080
RERANKER_TIMEOUT=5000

# =============================================================================
# Text Processing
# =============================================================================
CHUNK_SIZE=16000
CHUNK_OVERLAP=1000
PARALLEL_BATCH_SIZE=3

# =============================================================================
# Deduplication Thresholds
# =============================================================================
EMBEDDING_SIMILARITY_THRESHOLD=0.85
RERANKER_VERIFICATION_THRESHOLD=0.9
STRING_SIMILARITY_THRESHOLD=0.95
VECTOR_DISTANCE_THRESHOLD=0.15

# =============================================================================
# Scoring Configuration
# =============================================================================
MIN_CONFIDENCE=0.3
MAX_QUOTES_PER_CLAIM=10
MIN_QUOTE_RELEVANCE=0.85

# =============================================================================
# Quote Optimization (Coarse Chunking + DSPy)
# =============================================================================
# Coarse chunk size in tokens (reduces embeddings by 50x vs fine-grained segments)
COARSE_CHUNK_SIZE=3000
# Overlap between coarse chunks in tokens
COARSE_CHUNK_OVERLAP=500
# Number of top relevant chunks to retrieve per claim
TOP_K_CHUNKS=4
# Minimum confidence threshold for quote verification (0.0-1.0)
# 0.90 = strict, 0.85 = moderate, 0.80 = lenient
QUOTE_VERIFICATION_MIN_CONFIDENCE=0.90
# Path to optimized DSPy QuoteFinder model (leave empty to use zero-shot baseline)
QUOTE_FINDER_MODEL_PATH=models/quote_finder_v1.json

# =============================================================================
# DSPy Optimization (applies to all training: claims, entailment, quotes)
# =============================================================================
# Number of bootstrapped few-shot examples in prompts (more = better quality, slower inference)
DSPY_MAX_BOOTSTRAPPED_DEMOS=4
# Number of seed examples in prompts (internally set to match BOOTSTRAPPED_DEMOS)
DSPY_MAX_LABELED_DEMOS=2
# Optimization rounds (more = better quality, longer training time)
DSPY_MAX_ROUNDS=3
# Maximum errors tolerated during optimization before failing
DSPY_MAX_ERRORS=5

# =============================================================================
# Caching
# =============================================================================
CACHE_MAX_SIZE=10000
CACHE_TTL_HOURS=1

# =============================================================================
# Logging
# =============================================================================
LOG_LEVEL=INFO
